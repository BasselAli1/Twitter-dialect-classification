{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c1956e7",
   "metadata": {},
   "source": [
    "#### Deep learning training\n",
    "   1. [Reading the data (phase 2)](#phase2)\n",
    "   2. [convert the dialgect to numbers](#convert)\n",
    "   3. [Split the data to trainging and test data](#Split)\n",
    "   4. [tokenize the tweets and convert the labels to numbers](#tokenize)\n",
    "   5. [loading mazajak word embedding and training the model](#loading_mazajak)\n",
    "   6. [loading AraVec word embedding and training the model](#loading_AraVec)\n",
    "   7. [pretrained word embedding (mazajak)](#pretrained_word_embedding_mazajak)\n",
    "   8. [pretrained word embedding (AraVec)](#pretrained_word_embedding_AraVec)\n",
    "   9. [LSTM from scratch](#LSTM) \n",
    "   10. [Embeddding layer without LSTM from scratch](#Embeddding)\n",
    "   11. [Fine tuning pretrained word embedding(AraVec)](#Fine_tuning_pretrained_word_embedding_AraVec)\n",
    "   12. [Fine tuning pretrained word embedding(mazajak)](#Fine_tuning_pretrained_word_embedding_mazajak)\n",
    "   13. [loading DL model](#loading)\n",
    "   14. [testing DL models](#testing_DL)\n",
    "   \n",
    "#### Machine learning training  \n",
    "   1. [Cross validation to choose the best model](#Cross)\n",
    "   2. [Linear SVM](#SVM)\n",
    "   3. [testing ML models](#testing_ML)\n",
    "   4. [ML vs DL](#vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65db3343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU,Dense, Dropout, SpatialDropout1D, GlobalAveragePooling1D, LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump\n",
    "import tensorflow\n",
    "import gensim\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import joblib\n",
    "from dicts import preprocess, country_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9b78a4",
   "metadata": {},
   "source": [
    "### reading preprocessed data<a id='phase2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97143399",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"preprocessed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9214a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing one bad data point where the entire tweet is english\n",
    "dataset = dataset.drop(dataset['tweet'][dataset['pure_tweet'].isnull()].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f43f19",
   "metadata": {},
   "source": [
    "### converting the labels to numbers<a id='convert'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "911be6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['dialect_number'] = dataset['dialect'].factorize()[0]\n",
    "outputs = dict(zip(dataset['dialect_number'], dataset['dialect']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a3cb20",
   "metadata": {},
   "source": [
    "### splitting the data to train, validation and test <a id='Split'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee52844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_other, y_train, y_other = train_test_split(dataset, dataset['dialect_number'],test_size = 0.2, random_state =0)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_other, y_other,test_size = 0.5, random_state =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714740d1",
   "metadata": {},
   "source": [
    "### tokenize the tweets and convert the labels to numbers<a id='tokenize'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1216a0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train['pure_tweet'])\n",
    "encoded_docs = tokenizer.texts_to_sequences(X_train['pure_tweet'])\n",
    "y= to_categorical(y_train,num_classes=18)\n",
    "padded_sequence = pad_sequences(encoded_docs, maxlen=60, padding='post')\n",
    "y_val_categorical= to_categorical(y_val,num_classes=18)\n",
    "vocab_size = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7bdb151",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tweets = tokenizer.texts_to_sequences(X_val['pure_tweet'])\n",
    "val_padded_sequence = pad_sequences(val_tweets, maxlen=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "490494c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167970"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52acf720",
   "metadata": {},
   "source": [
    "### Mazajak Pretrained word embedding<a id='loading_mazajak'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb70141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_Mazajak = gensim.models.KeyedVectors.load_word2vec_format('cbow_100.bin',binary=True,unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b02be63",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix_Mazajak = np.zeros((vocab_size, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    try:\n",
    "        embedding_vector = embeddings_Mazajak[word]\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix_Mazajak[i] = embedding_vector\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9311621e",
   "metadata": {},
   "source": [
    "### AraVec word embedding<a id='loading_AraVec'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef4dd1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_AraVec = gensim.models.Word2Vec.load('full_uni_cbow_100_twitter.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e339d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix_AraVec = np.zeros((vocab_size, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    try:\n",
    "        embedding_vector = embeddings_AraVec[word]\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix_AraVec[i] = embedding_vector\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9329fb6",
   "metadata": {},
   "source": [
    "#### Callbacks(early stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8d1d8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', verbose=1, patience=2, min_delta= .1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacdb573",
   "metadata": {},
   "source": [
    "### experiement 1<a id='pretrained_word_embedding_mazajak'></a>\n",
    "#### LSTM with fixed pretrained word embedding (mazajak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47ef8f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_length = 300\n",
    "model_mazajak_LSTM = Sequential()\n",
    "model_mazajak_LSTM.add(Embedding(vocab_size, embedding_vector_length, weights=[embedding_matrix_Mazajak], trainable=False))\n",
    "model_mazajak_LSTM.add(LSTM(32, dropout=0.5, recurrent_dropout=0.5)) \n",
    "model_mazajak_LSTM.add(Dropout(0.2))\n",
    "model_mazajak_LSTM.add(Dense(18, activation='softmax'))\n",
    "model_mazajak_LSTM.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy']) #binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2178f227",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11455/11455 [==============================] - 1396s 122ms/step - loss: 2.3399 - accuracy: 0.2551 - val_loss: 2.2465 - val_accuracy: 0.2806\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.28055, saving model to best_model_mazajak_LSTM.h5\n",
      "Epoch 2/10\n",
      "11455/11455 [==============================] - 1381s 121ms/step - loss: 2.1297 - accuracy: 0.3221 - val_loss: 2.1631 - val_accuracy: 0.3140\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.28055 to 0.31399, saving model to best_model_mazajak_LSTM.h5\n",
      "Epoch 3/10\n",
      "11455/11455 [==============================] - 1375s 120ms/step - loss: 2.0644 - accuracy: 0.3445 - val_loss: 2.1688 - val_accuracy: 0.3113\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.31399\n",
      "Epoch 00003: early stopping\n"
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_mazajak_LSTM.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "history_mazajak_LSTM = model_mazajak_LSTM.fit(padded_sequence,y,validation_data=(val_padded_sequence, y_val_categorical),\n",
    "                                              epochs=10, batch_size=32, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aec35c2",
   "metadata": {},
   "source": [
    "### experiement 2<a id='pretrained_word_embedding_AraVec'></a>\n",
    "#### LSTM with fixed pretrained word embedding (AraVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5474a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_length = 100\n",
    "model_AraVec_LSTM = Sequential()\n",
    "model_AraVec_LSTM.add(Embedding(vocab_size, embedding_vector_length, weights=[embedding_matrix_AraVec], trainable=False))\n",
    "model_AraVec_LSTM.add(LSTM(32, dropout=0.5, recurrent_dropout=0.5)) \n",
    "model_AraVec_LSTM.add(Dropout(0.2))\n",
    "model_AraVec_LSTM.add(Dense(18, activation='softmax'))\n",
    "model_AraVec_LSTM.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy']) #binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcd65d7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11455/11455 [==============================] - 976s 85ms/step - loss: 2.7723 - accuracy: 0.1257 - val_loss: 2.7702 - val_accuracy: 0.1254\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.12543, saving model to best_model_AraVec_LSTM.h5\n",
      "Epoch 2/10\n",
      "11455/11455 [==============================] - 973s 85ms/step - loss: 2.7698 - accuracy: 0.1262 - val_loss: 2.7698 - val_accuracy: 0.1254\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.12543\n",
      "Epoch 3/10\n",
      "11455/11455 [==============================] - 1007s 88ms/step - loss: 2.7696 - accuracy: 0.1262 - val_loss: 2.7695 - val_accuracy: 0.1254\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.12543\n",
      "Epoch 4/10\n",
      "11455/11455 [==============================] - 999s 87ms/step - loss: 2.7694 - accuracy: 0.1262 - val_loss: 2.7695 - val_accuracy: 0.1254\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.12543\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_AraVec_LSTM.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "history_AraVec_LSTM = model_AraVec_LSTM.fit(padded_sequence,y, validation_data=(val_padded_sequence, y_val_categorical),\n",
    "                                            epochs=10, batch_size=32, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eddcd37",
   "metadata": {},
   "source": [
    "### experiment 3  <a id='LSTM'></a>\n",
    "LSTM from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c275ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_length = 100\n",
    "model_scratch = Sequential()\n",
    "model_scratch.add(Embedding(vocab_size, embedding_vector_length))\n",
    "model_scratch.add(LSTM(32, dropout=0.5, recurrent_dropout=0.5)) \n",
    "model_scratch.add(Dropout(0.2))\n",
    "model_scratch.add(Dense(18, activation='softmax'))\n",
    "model_scratch.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "710a0be2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11455/11455 [==============================] - 3596s 313ms/step - loss: 2.7725 - accuracy: 0.1257 - val_loss: 2.7608 - val_accuracy: 0.1255\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.12551, saving model to best_model_from_scratch.h5\n",
      "Epoch 2/10\n",
      "11455/11455 [==============================] - 3421s 299ms/step - loss: 2.7178 - accuracy: 0.1429 - val_loss: 2.5890 - val_accuracy: 0.1773\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.12551 to 0.17730, saving model to best_model_from_scratch.h5\n",
      "Epoch 3/10\n",
      "11455/11455 [==============================] - 3358s 293ms/step - loss: 2.0670 - accuracy: 0.3346 - val_loss: 2.1005 - val_accuracy: 0.3738\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.17730 to 0.37381, saving model to best_model_from_scratch.h5\n",
      "Epoch 4/10\n",
      "11455/11455 [==============================] - 3327s 290ms/step - loss: 1.7010 - accuracy: 0.4621 - val_loss: 2.0063 - val_accuracy: 0.4331\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.37381 to 0.43311, saving model to best_model_from_scratch.h5\n",
      "Epoch 5/10\n",
      "11455/11455 [==============================] - 3225s 282ms/step - loss: 1.4957 - accuracy: 0.5363 - val_loss: 1.9507 - val_accuracy: 0.4544\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.43311 to 0.45439, saving model to best_model_from_scratch.h5\n",
      "Epoch 6/10\n",
      "11455/11455 [==============================] - 3194s 279ms/step - loss: 1.3527 - accuracy: 0.5866 - val_loss: 1.9678 - val_accuracy: 0.4515\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.45439\n",
      "Epoch 7/10\n",
      "11455/11455 [==============================] - 3195s 279ms/step - loss: 1.2526 - accuracy: 0.6211 - val_loss: 1.9469 - val_accuracy: 0.4559\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.45439 to 0.45589, saving model to best_model_from_scratch.h5\n",
      "Epoch 8/10\n",
      "11455/11455 [==============================] - 3193s 279ms/step - loss: 1.1855 - accuracy: 0.6427 - val_loss: 1.9811 - val_accuracy: 0.4500\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.45589\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_from_scratch.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "history_scratch = model_scratch.fit(padded_sequence,y, validation_data=(val_padded_sequence, y_val_categorical)\n",
    "                                    , epochs=10, batch_size=32, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c5524b",
   "metadata": {},
   "source": [
    "### experiment 4 <a id='Embeddding'></a>\n",
    "Embeddding layer without LSTM from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "efa9ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_length = 100\n",
    "model_embeddding = Sequential()\n",
    "model_embeddding.add(Embedding(vocab_size, embedding_vector_length))\n",
    "model_embeddding.add(GlobalAveragePooling1D())\n",
    "\n",
    "model_embeddding.add(Dropout(0.2))\n",
    "model_embeddding.add(Dense(18, activation='softmax'))\n",
    "model_embeddding.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy']) #binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "718a3bfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11455/11455 [==============================] - 2525s 220ms/step - loss: 2.1130 - accuracy: 0.3591 - val_loss: 1.7617 - val_accuracy: 0.4720\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.47204, saving model to best_model_from_Embeddding.h5\n",
      "Epoch 2/10\n",
      "11455/11455 [==============================] - 2312s 202ms/step - loss: 1.6050 - accuracy: 0.5180 - val_loss: 1.6176 - val_accuracy: 0.5106\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.47204 to 0.51063, saving model to best_model_from_Embeddding.h5\n",
      "Epoch 3/10\n",
      "11455/11455 [==============================] - 2411s 210ms/step - loss: 1.4339 - accuracy: 0.5692 - val_loss: 1.5789 - val_accuracy: 0.5199\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.51063 to 0.51986, saving model to best_model_from_Embeddding.h5\n",
      "Epoch 4/10\n",
      "11455/11455 [==============================] - 2383s 208ms/step - loss: 1.3197 - accuracy: 0.6029 - val_loss: 1.5712 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.51986 to 0.52383, saving model to best_model_from_Embeddding.h5\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_from_Embeddding.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "history_embeddding = model_embeddding.fit(padded_sequence,y, validation_data=(val_padded_sequence, y_val_categorical)\n",
    "                                          , epochs=10, batch_size=32, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3938b58",
   "metadata": {},
   "source": [
    "### experiment 5 <a id='Fine_tuning_pretrained_word_embedding_AraVec'></a>\n",
    "Fine tuning pretrained word embedding(AraVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ce4d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_length = 100\n",
    "model_finetune_AraVec = Sequential()\n",
    "model_finetune_AraVec.add(Embedding(vocab_size, embedding_vector_length, weights=[embedding_matrix_AraVec]))\n",
    "model_finetune_AraVec.add(GlobalAveragePooling1D())\n",
    "model_finetune_AraVec.add(Dropout(0.2))\n",
    "model_finetune_AraVec.add(Dense(18, activation='softmax'))\n",
    "model_finetune_AraVec.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b31e8916",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11455/11455 [==============================] - 2574s 225ms/step - loss: 2.1127 - accuracy: 0.3573 - val_loss: 1.7632 - val_accuracy: 0.4681\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.46809, saving model to best_model_finetune_AraVec.h5\n",
      "Epoch 2/10\n",
      "11455/11455 [==============================] - 2422s 211ms/step - loss: 1.6064 - accuracy: 0.5156 - val_loss: 1.6200 - val_accuracy: 0.5067\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.46809 to 0.50670, saving model to best_model_finetune_AraVec.h5\n",
      "Epoch 3/10\n",
      "11455/11455 [==============================] - 2336s 204ms/step - loss: 1.4357 - accuracy: 0.5677 - val_loss: 1.5803 - val_accuracy: 0.5211\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.50670 to 0.52106, saving model to best_model_finetune_AraVec.h5\n",
      "Epoch 4/10\n",
      "11455/11455 [==============================] - 2383s 208ms/step - loss: 1.3219 - accuracy: 0.6019 - val_loss: 1.5676 - val_accuracy: 0.5241\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.52106 to 0.52407, saving model to best_model_finetune_AraVec.h5\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_finetune_AraVec.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "history_finetune_AraVec = model_finetune_AraVec.fit(padded_sequence,y, validation_data=(val_padded_sequence, y_val_categorical),\n",
    "                                               epochs=10, batch_size=32, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080750ad",
   "metadata": {},
   "source": [
    "### experiment 6 <a id='Fine_tuning_pretrained_word_embedding_mazajak'></a>\n",
    "Fine tuning pretrained word embedding(mazajak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fa6648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_length = 300\n",
    "model_finetune_mazajak = Sequential()\n",
    "model_finetune_mazajak.add(Embedding(vocab_size, embedding_vector_length, weights=[embedding_matrix_Mazajak]))\n",
    "model_finetune_mazajak.add(GlobalAveragePooling1D())\n",
    "model_finetune_mazajak.add(Dropout(0.2))\n",
    "model_finetune_mazajak.add(Dense(18, activation='softmax'))\n",
    "model_finetune_mazajak.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e3d362a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11455/11455 [==============================] - 6958s 607ms/step - loss: 1.9411 - accuracy: 0.4093 - val_loss: 1.6900 - val_accuracy: 0.4861\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.48608, saving model to best_model_finetune_mazajak.h5\n",
      "Epoch 2/10\n",
      "11455/11455 [==============================] - 6764s 590ms/step - loss: 1.5792 - accuracy: 0.5187 - val_loss: 1.5967 - val_accuracy: 0.5133\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.48608 to 0.51327, saving model to best_model_finetune_mazajak.h5\n",
      "Epoch 3/10\n",
      "11455/11455 [==============================] - 6750s 589ms/step - loss: 1.4429 - accuracy: 0.5611 - val_loss: 1.5698 - val_accuracy: 0.5199\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.51327 to 0.51990, saving model to best_model_finetune_mazajak.h5\n",
      "Epoch 4/10\n",
      "11455/11455 [==============================] - 6790s 593ms/step - loss: 1.3450 - accuracy: 0.5906 - val_loss: 1.5603 - val_accuracy: 0.5266\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.51990 to 0.52665, saving model to best_model_finetune_mazajak.h5\n",
      "Epoch 5/10\n",
      "11455/11455 [==============================] - 7361s 643ms/step - loss: 1.2672 - accuracy: 0.6150 - val_loss: 1.5675 - val_accuracy: 0.5260\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.52665\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_finetune_mazajak.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "history_finetune_mazajak = model_finetune_mazajak.fit(padded_sequence,y, validation_data=(val_padded_sequence, y_val_categorical),\n",
    "                                               epochs=10, batch_size=32, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02a3ff0",
   "metadata": {},
   "source": [
    "### Load models<a id='loading'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02286024",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_from_Embeddding = tensorflow.keras.models.load_model(\"best_model_from_Embeddding.h5\")\n",
    "best_model_from_scratch = tensorflow.keras.models.load_model(\"best_model_from_scratch.h5\")\n",
    "\n",
    "best_model_mazajak_LSTM = tensorflow.keras.models.load_model(\"best_model_mazajak_LSTM.h5\")\n",
    "best_model_AraVec_LSTM = tensorflow.keras.models.load_model(\"best_model_AraVec_LSTM.h5\")\n",
    "\n",
    "best_model_finetune_mazajak = tensorflow.keras.models.load_model(\"best_model_finetune_mazajak.h5\")\n",
    "best_model_finetune_AraVec = tensorflow.keras.models.load_model(\"best_model_finetune_AraVec.h5\")\n",
    "deep_learning_models = {'best_model_from_Embeddding':best_model_from_Embeddding,\n",
    "                       'best_model_from_scratch':best_model_from_scratch,\n",
    "                       'best_model_finetune_AraVec':best_model_finetune_AraVec,\n",
    "                       'best_model_finetune_mazajak':best_model_finetune_mazajak,\n",
    "                       'best_model_mazajak_LSTM':best_model_mazajak_LSTM,\n",
    "                       'best_model_AraVec_LSTM':best_model_AraVec_LSTM}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3433ae3",
   "metadata": {},
   "source": [
    "### Testing DL models<a id='testing_DL'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359111f7",
   "metadata": {},
   "source": [
    "#### tokenize and pad test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "857f7a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets = tokenizer.texts_to_sequences(X_test['pure_tweet'])\n",
    "test_padded_sequence = pad_sequences(test_tweets, maxlen=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455b22ea",
   "metadata": {},
   "source": [
    "### on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90f4a6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model_from_Embeddding  accuracy:  0.5238323876036666 || F1-score:  0.4941769939744494\n",
      "best_model_from_scratch  accuracy:  0.45589262330859887 || F1-score:  0.3992942075421435\n",
      "best_model_finetune_AraVec  accuracy:  0.524072457442165 || F1-score:  0.49355732044822276\n",
      "best_model_finetune_mazajak  accuracy:  0.5266477520733305 || F1-score:  0.4977199961273737\n",
      "best_model_mazajak_LSTM  accuracy:  0.31398952422522913 || F1-score:  0.1816254750301616\n",
      "best_model_AraVec_LSTM  accuracy:  0.1254255783500655 || F1-score:  0.01238302704356576\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in deep_learning_models.items():    \n",
    "    f = model.predict(val_padded_sequence)\n",
    "    print(model_name,' accuracy: ',np.mean(list(map(np.argmax,f))==y_val), '|| F1-score: ', f1_score(y_val, np.argmax(f,axis=1), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20717d8f",
   "metadata": {},
   "source": [
    "### on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b45ae440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.5288302051505893  ||F1 score:  0.5024157162774612\n"
     ]
    }
   ],
   "source": [
    "test_pred = model_finetune_mazajak.predict(test_padded_sequence)\n",
    "print('accuracy: ', np.mean(list(map(np.argmax,test_pred))==y_test),' ||F1 score: ', f1_score(y_test, np.argmax(test_pred,axis=1), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce3affae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dl(index, model, padding_max_len):\n",
    "    tw = tokenizer.texts_to_sequences([X_test['pure_tweet'].iloc[index]])\n",
    "    tw = pad_sequences(tw, maxlen=padding_max_len)\n",
    "    prediction = np.argmax(model.predict(tw))\n",
    "    print(X_test['tweet'].iloc[index])\n",
    "    print(\"ground truth: \", X_test['dialect'].iloc[index])\n",
    "    print(\"Predicted label: \", outputs[prediction], ' with propability: ', np.max(model.predict(tw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0792c862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@razan_alshamali عشان اصورك صور حلوة اليوم 😜😜😂😂😂\n",
      "ground truth:  PL\n",
      "Predicted label:  PL  with propability:  0.17330182\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "test_dl(index= index, model= best_model_from_Embeddding, padding_max_len=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b144bacd",
   "metadata": {},
   "source": [
    "## Machine learning<a id='testing_DL'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b107cf34",
   "metadata": {},
   "source": [
    "### Cross validation to choose the best model<a id='Cross'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "032fb9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    SGDClassifier(random_state=0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95428161",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = 3\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "775540a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('count', CountVectorizer()),\n",
    "                 ('tfid', TfidfTransformer())]).fit(X_train['pure_tweet'])\n",
    "pipe_train = pipe.transform(X_train['pure_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "91bd29d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC 0 0.499795393907649\n",
      "LinearSVC 1 0.49803985759299424\n",
      "LinearSVC 2 0.5005278880386299\n",
      "MultinomialNB 0 0.3594028775800828\n",
      "MultinomialNB 1 0.35778532553095715\n",
      "MultinomialNB 2 0.35985595613209476\n",
      "SGDClassifier 0 0.46497962123320186\n",
      "SGDClassifier 1 0.46164422801489546\n",
      "SGDClassifier 2 0.46435323484879487\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Standard deviation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.499454</td>\n",
       "      <td>0.001279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.359015</td>\n",
       "      <td>0.001089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.463659</td>\n",
       "      <td>0.001773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Mean Accuracy  Standard deviation\n",
       "model_name                                      \n",
       "LinearSVC           0.499454            0.001279\n",
       "MultinomialNB       0.359015            0.001089\n",
       "SGDClassifier       0.463659            0.001773"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, pipe.transform(X_train['pure_tweet']), y_train, scoring='accuracy', cv=CV)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "        print(model_name, fold_idx, accuracy)\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "\n",
    "mean_accuracy = cv_df.groupby('model_name').accuracy.mean()\n",
    "std_accuracy = cv_df.groupby('model_name').accuracy.std()\n",
    "\n",
    "acc = pd.concat([mean_accuracy, std_accuracy], axis= 1, \n",
    "          ignore_index=True)\n",
    "acc.columns = ['Mean Accuracy', 'Standard deviation']\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ee4337",
   "metadata": {},
   "source": [
    "### Linear SVM with tf-idf 2-grams<a id='SVM'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad9a3738",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_gram_svm = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer(ngram_range=(1,2))),\n",
    "    ('clf', LinearSVC()),\n",
    "])\n",
    "two_gram_svm.fit(X_train['pure_tweet'], y_train)\n",
    "uni_gram_svm = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer()),\n",
    "    ('clf', LinearSVC()),\n",
    "])\n",
    "uni_gram_svm.fit(X_train['pure_tweet'], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22282e1e",
   "metadata": {},
   "source": [
    "### testing ML on validation data<a id='testing_ML'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7c0f9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uni-gram\n",
      "accuracy:  0.512461807071148\n",
      "macro F1 score:  0.47850441725394727\n",
      "2-gram\n",
      "accuracy:  0.538018332605849\n",
      "macro F1 score:  0.5070792748737503\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "print(\"uni-gram\")\n",
    "print(\"accuracy: \", uni_gram_svm.score(X_val['pure_tweet'], y_val))\n",
    "print(\"macro F1 score: \", f1_score(y_val, uni_gram_svm.predict(X_val['pure_tweet']), average='macro'))\n",
    "print(\"2-gram\")\n",
    "print(\"accuracy: \", two_gram_svm.score(X_val['pure_tweet'], y_val))\n",
    "print(\"macro F1 score: \", f1_score(y_val, two_gram_svm.predict(X_val['pure_tweet']), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb99aca9",
   "metadata": {},
   "source": [
    "### testing the final model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a384d61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.5388476647752073\n",
      "macro F1 score:  0.5072461509724954\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: \", two_gram_svm.score(X_test['pure_tweet'], y_test))\n",
    "print(\"macro F1 score: \", f1_score(y_test, two_gram_svm.predict(X_test['pure_tweet']), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9509217e",
   "metadata": {},
   "source": [
    "### saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d5bcefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(two_gram_svm, filename= 'two_gram_svm.joblib')\n",
    "loaded_model = joblib.load('two_gram_svm.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcc283af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ml(model, index, type_of_model= 'other'):\n",
    "    if type_of_model =='train':\n",
    "        filtered_value = X_train['pure_tweet'].iloc[index]\n",
    "        print(X_train['tweet'].iloc[index])\n",
    "        print(\"prediction: \", model.predict([filtered_value])[0], \" \", outputs[model.predict([filtered_value])[0]])\n",
    "        print(\"Ground truth: \", X_train['dialect_number'].iloc[index], \" \", X_train['dialect'].iloc[index], \"\\n\")\n",
    "    elif type_of_model =='test':\n",
    "        filtered_value = X_test['pure_tweet'].iloc[index]\n",
    "        print(X_test['tweet'].iloc[index])\n",
    "        print(\"prediction: \",model.predict([filtered_value])[0], \" \", outputs[model.predict([filtered_value])[0]])\n",
    "        print(\"Ground truth: \", X_train['dialect_number'].iloc[index], \" \", X_train['dialect'].iloc[index], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50e41fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "من اجمل الاغاني اللي سمعتها هالايام \n",
      "\n",
      "🎹🎼🎵🎙\n",
      "أنا كل ما نويت أنسى\n",
      "لك الذكرى ترجعني\n",
      "وترى للحين أنا أحبك\n",
      "أشوفك بين حين وحين\n",
      "فراقك آه يا فراقك\n",
      "كسر قلبي وعذبني\n",
      "وأنا نذر علي\n",
      "أبقى أحبك لين يوم الدين\n",
      ".\n",
      "#انا_احبك \n",
      "#حسين_الجسمي \n",
      "@7sainaljassmi\n",
      "@aL9aNe3 https://t.co/jEYV6GDosC\n",
      "prediction:  17   BH\n",
      "Ground truth:  17   BH \n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 11\n",
    "test_ml(model= two_gram_svm, index= index, type_of_model= 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6986a57",
   "metadata": {},
   "source": [
    "## ML vs DL<a id='vs'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23be7168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_vs_dl(index, ml_model, dl_model):\n",
    "    filtered_value = X_test['pure_tweet'].iloc[index]\n",
    "    print(X_test['tweet'].iloc[index])\n",
    "    print(\"Ground truth: \", X_train['dialect'].iloc[index])\n",
    "    #print(model.predict([filtered_value]))\n",
    "    print(\"Ml predection: \", outputs[ml_model.predict([filtered_value])[0]])\n",
    "    tw = tokenizer.texts_to_sequences([filtered_value])\n",
    "    tw = pad_sequences(tw, maxlen=60)\n",
    "    prediction = np.argmax(dl_model.predict(tw))\n",
    "    print(\"dl predection: \", outputs[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9316dbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@razan_alshamali عشان اصورك صور حلوة اليوم 😜😜😂😂😂\n",
      "Ground truth:  BH\n",
      "Ml predection:  OM\n",
      "dl predection:  PL\n"
     ]
    }
   ],
   "source": [
    "index= 1\n",
    "ml_vs_dl(index= index, ml_model= two_gram_svm, dl_model= best_model_from_Embeddding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bfeef6",
   "metadata": {},
   "source": [
    "## ML vs DL for free text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a141d3ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from Data_pre_processing import preprocess\\ndef predict_free_text(ml_model, dl_model, text):\\n    processed_text = preprocess(text)\\n    print(\"machine learning: \", outputs[ml_model.predict([processed_text])[0]])\\n    tw = tokenizer.texts_to_sequences([processed_text])\\n    tw = pad_sequences(tw, maxlen=60)\\n    prediction = np.argmax(dl_model.predict(tw))\\n    print(\"deep learning: \",outputs[prediction])'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_free_text(ml_model, dl_model, text):\n",
    "    processed_text = preprocess(text)\n",
    "    print(\"machine learning: \", outputs[ml_model.predict([processed_text])[0]],'||', country_codes[outputs[ml_model.predict([processed_text])[0]]])\n",
    "    tw = tokenizer.texts_to_sequences([processed_text])\n",
    "    tw = pad_sequences(tw, maxlen=60)\n",
    "    prediction = np.argmax(dl_model.predict(tw))\n",
    "    print(\"deep learning: \",outputs[prediction],'||', country_codes[outputs[prediction]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "119fc0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter any text you want\n",
    "predict_free_text(ml_model = two_gram_svm, dl_model= best_model_finetune_mazajak, text= \"انا معرفش اسمك ايه\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04037fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
