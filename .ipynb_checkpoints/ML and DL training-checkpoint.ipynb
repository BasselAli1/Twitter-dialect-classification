{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c1956e7",
   "metadata": {},
   "source": [
    "#### Deep learning training\n",
    "   1. [Reading the data (phase 2)](#phase2)\n",
    "   2. [convert the dialgect to numbers](#convert)\n",
    "   3. [Split the data to trainging and test data](#Split)\n",
    "   4. [tokenize the tweets and convert the labels to numbers](#tokenize)\n",
    "   5. [loading mazajak word embedding and training the model](#loading_mazajak)\n",
    "   6. [loading AraVec word embedding and training the model](#loading_AraVec)\n",
    "   7. [pretrained word embedding (mazajak)](#pretrained_word_embedding_mazajak)\n",
    "   8. [pretrained word embedding (AraVec)](#pretrained_word_embedding_AraVec)\n",
    "   9. [LSTM from scratch](#LSTM) \n",
    "   10. [Embeddding layer without LSTM from scratch](#Embeddding)\n",
    "   11. [Fine tuning pretrained word embedding(AraVec)](#Fine_tuning_pretrained_word_embedding_AraVec)\n",
    "   12. [Fine tuning pretrained word embedding(mazajak)](#Fine_tuning_pretrained_word_embedding_mazajak)\n",
    "   13. [loading DL model](#loading)\n",
    "   14. [testing DL models](#testing_DL)\n",
    "   \n",
    "#### Machine learning training  \n",
    "   1. [Cross validation to choose the best model](#Cross)\n",
    "   2. [Linear SVM](#SVM)\n",
    "   3. [testing ML models](#testing_ML)\n",
    "   4. [ML vs DL](#vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65db3343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU,Dense, Dropout, SpatialDropout1D, GlobalAveragePooling1D, LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump\n",
    "import tensorflow\n",
    "import gensim\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import joblib\n",
    "from dicts import preprocess, country_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9b78a4",
   "metadata": {},
   "source": [
    "### reading preprocessed data<a id='phase2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97143399",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"preprocessed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9214a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing one bad data point where the entire tweet is english\n",
    "dataset = dataset.drop(dataset['tweet'][dataset['pure_tweet'].isnull()].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f43f19",
   "metadata": {},
   "source": [
    "### converting the labels to numbers<a id='convert'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "911be6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['dialect_number'] = dataset['dialect'].factorize()[0]\n",
    "outputs = dict(zip(dataset['dialect_number'], dataset['dialect']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a3cb20",
   "metadata": {},
   "source": [
    "### splitting the data to train, validation and test <a id='Split'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee52844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_other, y_train, y_other = train_test_split(dataset, dataset['dialect_number'],test_size = 0.2, random_state =0)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_other, y_other,test_size = 0.5, random_state =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714740d1",
   "metadata": {},
   "source": [
    "### tokenize the tweets and convert the labels to numbers<a id='tokenize'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1216a0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train['pure_tweet'])\n",
    "encoded_docs = tokenizer.texts_to_sequences(X_train['pure_tweet'])\n",
    "y= to_categorical(y_train,num_classes=18)\n",
    "padded_sequence = pad_sequences(encoded_docs, maxlen=60, padding='post')\n",
    "y_val_categorical= to_categorical(y_val,num_classes=18)\n",
    "vocab_size = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7bdb151",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tweets = tokenizer.texts_to_sequences(X_val['pure_tweet'])\n",
    "val_padded_sequence = pad_sequences(val_tweets, maxlen=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "490494c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167970"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52acf720",
   "metadata": {},
   "source": [
    "### Mazajak Pretrained word embedding<a id='loading_mazajak'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb70141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_Mazajak = gensim.models.KeyedVectors.load_word2vec_format('cbow_100.bin',binary=True,unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b02be63",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix_Mazajak = np.zeros((vocab_size, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    try:\n",
    "        embedding_vector = embeddings_Mazajak[word]\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix_Mazajak[i] = embedding_vector\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9311621e",
   "metadata": {},
   "source": [
    "### AraVec word embedding<a id='loading_AraVec'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef4dd1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_AraVec = gensim.models.Word2Vec.load('full_uni_cbow_100_twitter.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e339d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix_AraVec = np.zeros((vocab_size, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    try:\n",
    "        embedding_vector = embeddings_AraVec[word]\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix_AraVec[i] = embedding_vector\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9329fb6",
   "metadata": {},
   "source": [
    "#### Callbacks(early stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8d1d8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', verbose=1, patience=2, min_delta= .1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacdb573",
   "metadata": {},
   "source": [
    "### experiement 1<a id='pretrained_word_embedding_mazajak'></a>\n",
    "#### LSTM with fixed pretrained word embedding (mazajak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47ef8f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_length = 300\n",
    "model_mazajak_LSTM = Sequential()\n",
    "model_mazajak_LSTM.add(Embedding(vocab_size, embedding_vector_length, weights=[embedding_matrix_Mazajak], trainable=False))\n",
    "model_mazajak_LSTM.add(LSTM(32, dropout=0.5, recurrent_dropout=0.5)) \n",
    "model_mazajak_LSTM.add(Dropout(0.2))\n",
    "model_mazajak_LSTM.add(Dense(18, activation='softmax'))\n",
    "model_mazajak_LSTM.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy']) #binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2178f227",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11455/11455 [==============================] - 1396s 122ms/step - loss: 2.3399 - accuracy: 0.2551 - val_loss: 2.2465 - val_accuracy: 0.2806\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.28055, saving model to best_model_mazajak_LSTM.h5\n",
      "Epoch 2/10\n",
      "11455/11455 [==============================] - 1381s 121ms/step - loss: 2.1297 - accuracy: 0.3221 - val_loss: 2.1631 - val_accuracy: 0.3140\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.28055 to 0.31399, saving model to best_model_mazajak_LSTM.h5\n",
      "Epoch 3/10\n",
      "11455/11455 [==============================] - 1375s 120ms/step - loss: 2.0644 - accuracy: 0.3445 - val_loss: 2.1688 - val_accuracy: 0.3113\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.31399\n",
      "Epoch 00003: early stopping\n"
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_mazajak_LSTM.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "history_mazajak_LSTM = model_mazajak_LSTM.fit(padded_sequence,y,validation_data=(val_padded_sequence, y_val_categorical),\n",
    "                                              epochs=10, batch_size=32, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aec35c2",
   "metadata": {},
   "source": [
    "### experiement 2<a id='pretrained_word_embedding_AraVec'></a>\n",
    "#### LSTM with fixed pretrained word embedding (AraVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5474a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_length = 100\n",
    "model_AraVec_LSTM = Sequential()\n",
    "model_AraVec_LSTM.add(Embedding(vocab_size, embedding_vector_length, weights=[embedding_matrix_AraVec], trainable=False))\n",
    "model_AraVec_LSTM.add(LSTM(32, dropout=0.5, recurrent_dropout=0.5)) \n",
    "model_AraVec_LSTM.add(Dropout(0.2))\n",
    "model_AraVec_LSTM.add(Dense(18, activation='softmax'))\n",
    "model_AraVec_LSTM.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy']) #binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcd65d7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11455/11455 [==============================] - 976s 85ms/step - loss: 2.7723 - accuracy: 0.1257 - val_loss: 2.7702 - val_accuracy: 0.1254\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.12543, saving model to best_model_AraVec_LSTM.h5\n",
      "Epoch 2/10\n",
      "11455/11455 [==============================] - 973s 85ms/step - loss: 2.7698 - accuracy: 0.1262 - val_loss: 2.7698 - val_accuracy: 0.1254\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.12543\n",
      "Epoch 3/10\n",
      "11455/11455 [==============================] - 1007s 88ms/step - loss: 2.7696 - accuracy: 0.1262 - val_loss: 2.7695 - val_accuracy: 0.1254\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.12543\n",
      "Epoch 4/10\n",
      "11455/11455 [==============================] - 999s 87ms/step - loss: 2.7694 - accuracy: 0.1262 - val_loss: 2.7695 - val_accuracy: 0.1254\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.12543\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_AraVec_LSTM.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "history_AraVec_LSTM = model_AraVec_LSTM.fit(padded_sequence,y, validation_data=(val_padded_sequence, y_val_categorical),\n",
    "                                            epochs=10, batch_size=32, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eddcd37",
   "metadata": {},
   "source": [
    "### experiment 3  <a id='LSTM'></a>\n",
    "LSTM from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c275ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_length = 100\n",
    "model_scratch = Sequential()\n",
    "model_scratch.add(Embedding(vocab_size, embedding_vector_length))\n",
    "model_scratch.add(LSTM(32, dropout=0.5, recurrent_dropout=0.5)) \n",
    "model_scratch.add(Dropout(0.2))\n",
    "model_scratch.add(Dense(18, activation='softmax'))\n",
    "model_scratch.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "710a0be2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11455/11455 [==============================] - 3596s 313ms/step - loss: 2.7725 - accuracy: 0.1257 - val_loss: 2.7608 - val_accuracy: 0.1255\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.12551, saving model to best_model_from_scratch.h5\n",
      "Epoch 2/10\n",
      "11455/11455 [==============================] - 3421s 299ms/step - loss: 2.7178 - accuracy: 0.1429 - val_loss: 2.5890 - val_accuracy: 0.1773\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.12551 to 0.17730, saving model to best_model_from_scratch.h5\n",
      "Epoch 3/10\n",
      "11455/11455 [==============================] - 3358s 293ms/step - loss: 2.0670 - accuracy: 0.3346 - val_loss: 2.1005 - val_accuracy: 0.3738\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.17730 to 0.37381, saving model to best_model_from_scratch.h5\n",
      "Epoch 4/10\n",
      "11455/11455 [==============================] - 3327s 290ms/step - loss: 1.7010 - accuracy: 0.4621 - val_loss: 2.0063 - val_accuracy: 0.4331\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.37381 to 0.43311, saving model to best_model_from_scratch.h5\n",
      "Epoch 5/10\n",
      "11455/11455 [==============================] - 3225s 282ms/step - loss: 1.4957 - accuracy: 0.5363 - val_loss: 1.9507 - val_accuracy: 0.4544\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.43311 to 0.45439, saving model to best_model_from_scratch.h5\n",
      "Epoch 6/10\n",
      "11455/11455 [==============================] - 3194s 279ms/step - loss: 1.3527 - accuracy: 0.5866 - val_loss: 1.9678 - val_accuracy: 0.4515\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.45439\n",
      "Epoch 7/10\n",
      "11455/11455 [==============================] - 3195s 279ms/step - loss: 1.2526 - accuracy: 0.6211 - val_loss: 1.9469 - val_accuracy: 0.4559\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.45439 to 0.45589, saving model to best_model_from_scratch.h5\n",
      "Epoch 8/10\n",
      "11455/11455 [==============================] - 3193s 279ms/step - loss: 1.1855 - accuracy: 0.6427 - val_loss: 1.9811 - val_accuracy: 0.4500\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.45589\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_from_scratch.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "history_scratch = model_scratch.fit(padded_sequence,y, validation_data=(val_padded_sequence, y_val_categorical)\n",
    "                                    , epochs=10, batch_size=32, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c5524b",
   "metadata": {},
   "source": [
    "### experiment 4 <a id='Embeddding'></a>\n",
    "Embeddding layer without LSTM from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "efa9ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_length = 100\n",
    "model_embeddding = Sequential()\n",
    "model_embeddding.add(Embedding(vocab_size, embedding_vector_length))\n",
    "model_embeddding.add(GlobalAveragePooling1D())\n",
    "\n",
    "model_embeddding.add(Dropout(0.2))\n",
    "model_embeddding.add(Dense(18, activation='softmax'))\n",
    "model_embeddding.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy']) #binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "718a3bfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11455/11455 [==============================] - 2525s 220ms/step - loss: 2.1130 - accuracy: 0.3591 - val_loss: 1.7617 - val_accuracy: 0.4720\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.47204, saving model to best_model_from_Embeddding.h5\n",
      "Epoch 2/10\n",
      "11455/11455 [==============================] - 2312s 202ms/step - loss: 1.6050 - accuracy: 0.5180 - val_loss: 1.6176 - val_accuracy: 0.5106\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.47204 to 0.51063, saving model to best_model_from_Embeddding.h5\n",
      "Epoch 3/10\n",
      "11455/11455 [==============================] - 2411s 210ms/step - loss: 1.4339 - accuracy: 0.5692 - val_loss: 1.5789 - val_accuracy: 0.5199\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.51063 to 0.51986, saving model to best_model_from_Embeddding.h5\n",
      "Epoch 4/10\n",
      "11455/11455 [==============================] - 2383s 208ms/step - loss: 1.3197 - accuracy: 0.6029 - val_loss: 1.5712 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.51986 to 0.52383, saving model to best_model_from_Embeddding.h5\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_from_Embeddding.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "history_embeddding = model_embeddding.fit(padded_sequence,y, validation_data=(val_padded_sequence, y_val_categorical)\n",
    "                                          , epochs=10, batch_size=32, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3938b58",
   "metadata": {},
   "source": [
    "### experiment 5 <a id='Fine_tuning_pretrained_word_embedding_AraVec'></a>\n",
    "Fine tuning pretrained word embedding(AraVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ce4d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_length = 100\n",
    "model_finetune_AraVec = Sequential()\n",
    "model_finetune_AraVec.add(Embedding(vocab_size, embedding_vector_length, weights=[embedding_matrix_AraVec]))\n",
    "model_finetune_AraVec.add(GlobalAveragePooling1D())\n",
    "model_finetune_AraVec.add(Dropout(0.2))\n",
    "model_finetune_AraVec.add(Dense(18, activation='softmax'))\n",
    "model_finetune_AraVec.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b31e8916",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11455/11455 [==============================] - 2574s 225ms/step - loss: 2.1127 - accuracy: 0.3573 - val_loss: 1.7632 - val_accuracy: 0.4681\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.46809, saving model to best_model_finetune_AraVec.h5\n",
      "Epoch 2/10\n",
      "11455/11455 [==============================] - 2422s 211ms/step - loss: 1.6064 - accuracy: 0.5156 - val_loss: 1.6200 - val_accuracy: 0.5067\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.46809 to 0.50670, saving model to best_model_finetune_AraVec.h5\n",
      "Epoch 3/10\n",
      "11455/11455 [==============================] - 2336s 204ms/step - loss: 1.4357 - accuracy: 0.5677 - val_loss: 1.5803 - val_accuracy: 0.5211\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.50670 to 0.52106, saving model to best_model_finetune_AraVec.h5\n",
      "Epoch 4/10\n",
      "11455/11455 [==============================] - 2383s 208ms/step - loss: 1.3219 - accuracy: 0.6019 - val_loss: 1.5676 - val_accuracy: 0.5241\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.52106 to 0.52407, saving model to best_model_finetune_AraVec.h5\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_finetune_AraVec.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "history_finetune_AraVec = model_finetune_AraVec.fit(padded_sequence,y, validation_data=(val_padded_sequence, y_val_categorical),\n",
    "                                               epochs=10, batch_size=32, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080750ad",
   "metadata": {},
   "source": [
    "### experiment 6 <a id='Fine_tuning_pretrained_word_embedding_mazajak'></a>\n",
    "Fine tuning pretrained word embedding(mazajak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fa6648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_length = 300\n",
    "model_finetune_mazajak = Sequential()\n",
    "model_finetune_mazajak.add(Embedding(vocab_size, embedding_vector_length, weights=[embedding_matrix_Mazajak]))\n",
    "model_finetune_mazajak.add(GlobalAveragePooling1D())\n",
    "model_finetune_mazajak.add(Dropout(0.2))\n",
    "model_finetune_mazajak.add(Dense(18, activation='softmax'))\n",
    "model_finetune_mazajak.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e3d362a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11455/11455 [==============================] - 6958s 607ms/step - loss: 1.9411 - accuracy: 0.4093 - val_loss: 1.6900 - val_accuracy: 0.4861\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.48608, saving model to best_model_finetune_mazajak.h5\n",
      "Epoch 2/10\n",
      "11455/11455 [==============================] - 6764s 590ms/step - loss: 1.5792 - accuracy: 0.5187 - val_loss: 1.5967 - val_accuracy: 0.5133\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.48608 to 0.51327, saving model to best_model_finetune_mazajak.h5\n",
      "Epoch 3/10\n",
      "11455/11455 [==============================] - 6750s 589ms/step - loss: 1.4429 - accuracy: 0.5611 - val_loss: 1.5698 - val_accuracy: 0.5199\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.51327 to 0.51990, saving model to best_model_finetune_mazajak.h5\n",
      "Epoch 4/10\n",
      "11455/11455 [==============================] - 6790s 593ms/step - loss: 1.3450 - accuracy: 0.5906 - val_loss: 1.5603 - val_accuracy: 0.5266\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.51990 to 0.52665, saving model to best_model_finetune_mazajak.h5\n",
      "Epoch 5/10\n",
      "11455/11455 [==============================] - 7361s 643ms/step - loss: 1.2672 - accuracy: 0.6150 - val_loss: 1.5675 - val_accuracy: 0.5260\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.52665\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_finetune_mazajak.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "history_finetune_mazajak = model_finetune_mazajak.fit(padded_sequence,y, validation_data=(val_padded_sequence, y_val_categorical),\n",
    "                                               epochs=10, batch_size=32, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02a3ff0",
   "metadata": {},
   "source": [
    "### Load models<a id='loading'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02286024",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_from_Embeddding = tensorflow.keras.models.load_model(\"best_model_from_Embeddding.h5\")\n",
    "best_model_from_scratch = tensorflow.keras.models.load_model(\"best_model_from_scratch.h5\")\n",
    "\n",
    "best_model_mazajak_LSTM = tensorflow.keras.models.load_model(\"best_model_mazajak_LSTM.h5\")\n",
    "best_model_AraVec_LSTM = tensorflow.keras.models.load_model(\"best_model_AraVec_LSTM.h5\")\n",
    "\n",
    "best_model_finetune_mazajak = tensorflow.keras.models.load_model(\"best_model_finetune_mazajak.h5\")\n",
    "best_model_finetune_AraVec = tensorflow.keras.models.load_model(\"best_model_finetune_AraVec.h5\")\n",
    "deep_learning_models = {'best_model_from_Embeddding':best_model_from_Embeddding,\n",
    "                       'best_model_from_scratch':best_model_from_scratch,\n",
    "                       'best_model_finetune_AraVec':best_model_finetune_AraVec,\n",
    "                       'best_model_finetune_mazajak':best_model_finetune_mazajak,\n",
    "                       'best_model_mazajak_LSTM':best_model_mazajak_LSTM,\n",
    "                       'best_model_AraVec_LSTM':best_model_AraVec_LSTM}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3433ae3",
   "metadata": {},
   "source": [
    "### Testing DL models<a id='testing_DL'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359111f7",
   "metadata": {},
   "source": [
    "#### tokenize and pad test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "857f7a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets = tokenizer.texts_to_sequences(X_test['pure_tweet'])\n",
    "test_padded_sequence = pad_sequences(test_tweets, maxlen=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455b22ea",
   "metadata": {},
   "source": [
    "### on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90f4a6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model_from_Embeddding  accuracy:  0.5238323876036666 || F1-score:  0.4941769939744494\n",
      "best_model_from_scratch  accuracy:  0.45589262330859887 || F1-score:  0.3992942075421435\n",
      "best_model_finetune_AraVec  accuracy:  0.524072457442165 || F1-score:  0.49355732044822276\n",
      "best_model_finetune_mazajak  accuracy:  0.5266477520733305 || F1-score:  0.4977199961273737\n",
      "best_model_mazajak_LSTM  accuracy:  0.31398952422522913 || F1-score:  0.1816254750301616\n",
      "best_model_AraVec_LSTM  accuracy:  0.1254255783500655 || F1-score:  0.01238302704356576\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in deep_learning_models.items():    \n",
    "    f = model.predict(val_padded_sequence)\n",
    "    print(model_name,' accuracy: ',np.mean(list(map(np.argmax,f))==y_val), '|| F1-score: ', f1_score(y_val, np.argmax(f,axis=1), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20717d8f",
   "metadata": {},
   "source": [
    "### on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b45ae440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.5288302051505893  ||F1 score:  0.5024157162774612\n"
     ]
    }
   ],
   "source": [
    "test_pred = model_finetune_mazajak.predict(test_padded_sequence)\n",
    "print('accuracy: ', np.mean(list(map(np.argmax,test_pred))==y_test),' ||F1 score: ', f1_score(y_test, np.argmax(test_pred,axis=1), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce3affae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dl(index, model, padding_max_len):\n",
    "    tw = tokenizer.texts_to_sequences([X_test['pure_tweet'].iloc[index]])\n",
    "    tw = pad_sequences(tw, maxlen=padding_max_len)\n",
    "    prediction = np.argmax(model.predict(tw))\n",
    "    print(X_test['tweet'].iloc[index])\n",
    "    print(\"ground truth: \", X_test['dialect'].iloc[index])\n",
    "    print(\"Predicted label: \", outputs[prediction], ' with propability: ', np.max(model.predict(tw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0792c862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@razan_alshamali ÿπÿ¥ÿßŸÜ ÿßÿµŸàÿ±ŸÉ ÿµŸàÿ± ÿ≠ŸÑŸàÿ© ÿßŸÑŸäŸàŸÖ üòúüòúüòÇüòÇüòÇ\n",
      "ground truth:  PL\n",
      "Predicted label:  PL  with propability:  0.17330182\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "test_dl(index= index, model= best_model_from_Embeddding, padding_max_len=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b144bacd",
   "metadata": {},
   "source": [
    "## Machine learning<a id='testing_DL'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b107cf34",
   "metadata": {},
   "source": [
    "### Cross validation to choose the best model<a id='Cross'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "032fb9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    SGDClassifier(random_state=0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95428161",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = 3\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "775540a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('count', CountVectorizer()),\n",
    "                 ('tfid', TfidfTransformer())]).fit(X_train['pure_tweet'])\n",
    "pipe_train = pipe.transform(X_train['pure_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "91bd29d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC 0 0.499795393907649\n",
      "LinearSVC 1 0.49803985759299424\n",
      "LinearSVC 2 0.5005278880386299\n",
      "MultinomialNB 0 0.3594028775800828\n",
      "MultinomialNB 1 0.35778532553095715\n",
      "MultinomialNB 2 0.35985595613209476\n",
      "SGDClassifier 0 0.46497962123320186\n",
      "SGDClassifier 1 0.46164422801489546\n",
      "SGDClassifier 2 0.46435323484879487\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Standard deviation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.499454</td>\n",
       "      <td>0.001279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.359015</td>\n",
       "      <td>0.001089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.463659</td>\n",
       "      <td>0.001773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Mean Accuracy  Standard deviation\n",
       "model_name                                      \n",
       "LinearSVC           0.499454            0.001279\n",
       "MultinomialNB       0.359015            0.001089\n",
       "SGDClassifier       0.463659            0.001773"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, pipe.transform(X_train['pure_tweet']), y_train, scoring='accuracy', cv=CV)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "        print(model_name, fold_idx, accuracy)\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "\n",
    "mean_accuracy = cv_df.groupby('model_name').accuracy.mean()\n",
    "std_accuracy = cv_df.groupby('model_name').accuracy.std()\n",
    "\n",
    "acc = pd.concat([mean_accuracy, std_accuracy], axis= 1, \n",
    "          ignore_index=True)\n",
    "acc.columns = ['Mean Accuracy', 'Standard deviation']\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ee4337",
   "metadata": {},
   "source": [
    "### Linear SVM with tf-idf 2-grams<a id='SVM'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad9a3738",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_gram_svm = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer(ngram_range=(1,2))),\n",
    "    ('clf', LinearSVC()),\n",
    "])\n",
    "two_gram_svm.fit(X_train['pure_tweet'], y_train)\n",
    "uni_gram_svm = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer()),\n",
    "    ('clf', LinearSVC()),\n",
    "])\n",
    "uni_gram_svm.fit(X_train['pure_tweet'], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22282e1e",
   "metadata": {},
   "source": [
    "### testing ML on validation data<a id='testing_ML'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7c0f9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uni-gram\n",
      "accuracy:  0.512461807071148\n",
      "macro F1 score:  0.47850441725394727\n",
      "2-gram\n",
      "accuracy:  0.538018332605849\n",
      "macro F1 score:  0.5070792748737503\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "print(\"uni-gram\")\n",
    "print(\"accuracy: \", uni_gram_svm.score(X_val['pure_tweet'], y_val))\n",
    "print(\"macro F1 score: \", f1_score(y_val, uni_gram_svm.predict(X_val['pure_tweet']), average='macro'))\n",
    "print(\"2-gram\")\n",
    "print(\"accuracy: \", two_gram_svm.score(X_val['pure_tweet'], y_val))\n",
    "print(\"macro F1 score: \", f1_score(y_val, two_gram_svm.predict(X_val['pure_tweet']), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb99aca9",
   "metadata": {},
   "source": [
    "### testing the final model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a384d61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.5388476647752073\n",
      "macro F1 score:  0.5072461509724954\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: \", two_gram_svm.score(X_test['pure_tweet'], y_test))\n",
    "print(\"macro F1 score: \", f1_score(y_test, two_gram_svm.predict(X_test['pure_tweet']), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9509217e",
   "metadata": {},
   "source": [
    "### saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d5bcefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(two_gram_svm, filename= 'two_gram_svm.joblib')\n",
    "loaded_model = joblib.load('two_gram_svm.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcc283af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ml(model, index, type_of_model= 'other'):\n",
    "    if type_of_model =='train':\n",
    "        filtered_value = X_train['pure_tweet'].iloc[index]\n",
    "        print(X_train['tweet'].iloc[index])\n",
    "        print(\"prediction: \", model.predict([filtered_value])[0], \" \", outputs[model.predict([filtered_value])[0]])\n",
    "        print(\"Ground truth: \", X_train['dialect_number'].iloc[index], \" \", X_train['dialect'].iloc[index], \"\\n\")\n",
    "    elif type_of_model =='test':\n",
    "        filtered_value = X_test['pure_tweet'].iloc[index]\n",
    "        print(X_test['tweet'].iloc[index])\n",
    "        print(\"prediction: \",model.predict([filtered_value])[0], \" \", outputs[model.predict([filtered_value])[0]])\n",
    "        print(\"Ground truth: \", X_train['dialect_number'].iloc[index], \" \", X_train['dialect'].iloc[index], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50e41fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ŸÖŸÜ ÿßÿ¨ŸÖŸÑ ÿßŸÑÿßÿ∫ÿßŸÜŸä ÿßŸÑŸÑŸä ÿ≥ŸÖÿπÿ™Ÿáÿß ŸáÿßŸÑÿßŸäÿßŸÖ \n",
      "\n",
      "üéπüéºüéµüéô\n",
      "ÿ£ŸÜÿß ŸÉŸÑ ŸÖÿß ŸÜŸàŸäÿ™ ÿ£ŸÜÿ≥Ÿâ\n",
      "ŸÑŸÉ ÿßŸÑÿ∞ŸÉÿ±Ÿâ ÿ™ÿ±ÿ¨ÿπŸÜŸä\n",
      "Ÿàÿ™ÿ±Ÿâ ŸÑŸÑÿ≠ŸäŸÜ ÿ£ŸÜÿß ÿ£ÿ≠ÿ®ŸÉ\n",
      "ÿ£ÿ¥ŸàŸÅŸÉ ÿ®ŸäŸÜ ÿ≠ŸäŸÜ Ÿàÿ≠ŸäŸÜ\n",
      "ŸÅÿ±ÿßŸÇŸÉ ÿ¢Ÿá Ÿäÿß ŸÅÿ±ÿßŸÇŸÉ\n",
      "ŸÉÿ≥ÿ± ŸÇŸÑÿ®Ÿä Ÿàÿπÿ∞ÿ®ŸÜŸä\n",
      "Ÿàÿ£ŸÜÿß ŸÜÿ∞ÿ± ÿπŸÑŸä\n",
      "ÿ£ÿ®ŸÇŸâ ÿ£ÿ≠ÿ®ŸÉ ŸÑŸäŸÜ ŸäŸàŸÖ ÿßŸÑÿØŸäŸÜ\n",
      ".\n",
      "#ÿßŸÜÿß_ÿßÿ≠ÿ®ŸÉ \n",
      "#ÿ≠ÿ≥ŸäŸÜ_ÿßŸÑÿ¨ÿ≥ŸÖŸä \n",
      "@7sainaljassmi\n",
      "@aL9aNe3 https://t.co/jEYV6GDosC\n",
      "prediction:  17   BH\n",
      "Ground truth:  17   BH \n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 11\n",
    "test_ml(model= two_gram_svm, index= index, type_of_model= 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6986a57",
   "metadata": {},
   "source": [
    "## ML vs DL<a id='vs'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23be7168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_vs_dl(index, ml_model, dl_model):\n",
    "    filtered_value = X_test['pure_tweet'].iloc[index]\n",
    "    print(X_test['tweet'].iloc[index])\n",
    "    print(\"Ground truth: \", X_train['dialect'].iloc[index])\n",
    "    #print(model.predict([filtered_value]))\n",
    "    print(\"Ml predection: \", outputs[ml_model.predict([filtered_value])[0]])\n",
    "    tw = tokenizer.texts_to_sequences([filtered_value])\n",
    "    tw = pad_sequences(tw, maxlen=60)\n",
    "    prediction = np.argmax(dl_model.predict(tw))\n",
    "    print(\"dl predection: \", outputs[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9316dbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@razan_alshamali ÿπÿ¥ÿßŸÜ ÿßÿµŸàÿ±ŸÉ ÿµŸàÿ± ÿ≠ŸÑŸàÿ© ÿßŸÑŸäŸàŸÖ üòúüòúüòÇüòÇüòÇ\n",
      "Ground truth:  BH\n",
      "Ml predection:  OM\n",
      "dl predection:  PL\n"
     ]
    }
   ],
   "source": [
    "index= 1\n",
    "ml_vs_dl(index= index, ml_model= two_gram_svm, dl_model= best_model_from_Embeddding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bfeef6",
   "metadata": {},
   "source": [
    "## ML vs DL for free text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a141d3ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from Data_pre_processing import preprocess\\ndef predict_free_text(ml_model, dl_model, text):\\n    processed_text = preprocess(text)\\n    print(\"machine learning: \", outputs[ml_model.predict([processed_text])[0]])\\n    tw = tokenizer.texts_to_sequences([processed_text])\\n    tw = pad_sequences(tw, maxlen=60)\\n    prediction = np.argmax(dl_model.predict(tw))\\n    print(\"deep learning: \",outputs[prediction])'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_free_text(ml_model, dl_model, text):\n",
    "    processed_text = preprocess(text)\n",
    "    print(\"machine learning: \", outputs[ml_model.predict([processed_text])[0]],'||', country_codes[outputs[ml_model.predict([processed_text])[0]]])\n",
    "    tw = tokenizer.texts_to_sequences([processed_text])\n",
    "    tw = pad_sequences(tw, maxlen=60)\n",
    "    prediction = np.argmax(dl_model.predict(tw))\n",
    "    print(\"deep learning: \",outputs[prediction],'||', country_codes[outputs[prediction]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "119fc0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter any text you want\n",
    "predict_free_text(ml_model = two_gram_svm, dl_model= best_model_finetune_mazajak, text= \"ÿßŸÜÿß ŸÖÿπÿ±ŸÅÿ¥ ÿßÿ≥ŸÖŸÉ ÿßŸäŸá\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04037fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
